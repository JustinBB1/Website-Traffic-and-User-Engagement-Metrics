"""
Script d'exploration du dataset Website Traffic
ExÃ©cute : python scripts/explore_data.py
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os

# CrÃ©er le dossier dataset s'il n'existe pas
os.makedirs('dataset', exist_ok=True)

print("="*60)
print("ANALYSE DU DATASET : WEBSITE TRAFFIC")
print("="*60)

# 1. Charger les donnÃ©es (assure-toi que le fichier est au bon endroit)
try:
    df = pd.read_csv('dataset/website_wata.csv')
    print("âœ… Dataset chargÃ© avec succÃ¨s!")
except FileNotFoundError:
    print("âŒ Fichier non trouvÃ©. Place 'website_traffic.csv' dans le dossier 'dataset/'")
    exit()

# 2. Informations gÃ©nÃ©rales
print(f"\nðŸ“Š TAILLE DU DATASET : {df.shape[0]} lignes, {df.shape[1]} colonnes")

print("\nðŸ“‹ COLONNES DISPONIBLES :")
for i, col in enumerate(df.columns, 1):
    dtype = df[col].dtype
    print(f"  {i:2d}. {col:20} ({dtype}) - Exemple: {df[col].iloc[0]}")

print("\nðŸ” APERÃ‡U DES DONNÃ‰ES (5 premiÃ¨res lignes) :")
print(df.head())

print("\nðŸ“ˆ STATISTIQUES DESCRIPTIVES :")
print(df.describe())

print("\nâ“ VALEURS MANQUANTES :")
missing = df.isnull().sum()
for col in df.columns:
    if missing[col] > 0:
        print(f"  {col}: {missing[col]} valeurs manquantes ({missing[col]/len(df)*100:.1f}%)")
    else:
        print(f"  {col}: Aucune valeur manquante âœ…")

print("\nðŸŽ¯ VALEURS UNIQUES PAR COLONNE :")
for col in df.columns:
    unique_count = df[col].nunique()
    if unique_count < 10:  # Si peu de valeurs uniques, les afficher
        print(f"  {col}: {unique_count} valeurs â†’ {df[col].unique()}")
    else:
        print(f"  {col}: {unique_count} valeurs uniques")

print("\nðŸŒ TRAFFIC SOURCE - DISTRIBUTION :")
if 'Traffic Source' in df.columns:
    source_counts = df['Traffic Source'].value_counts()
    print(source_counts)

# 3. CorrÃ©lations (si toutes les colonnes sont numÃ©riques)
print("\nðŸ“Š MATRICE DE CORRÃ‰LATION (colonnes numÃ©riques) :")
numeric_df = df.select_dtypes(include=[np.number])
if not numeric_df.empty:
    corr_matrix = numeric_df.corr()
    print(corr_matrix)
    
    # Visualisation (optionnel)
    plt.figure(figsize=(10, 8))
    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)
    plt.title('Matrice de corrÃ©lation')
    plt.tight_layout()
    plt.savefig('dataset/correlation_heatmap.png', dpi=100)
    print("\nâœ… Heatmap sauvegardÃ©e : 'dataset/correlation_heatmap.png'")

# 4. Sauvegarder un Ã©chantillon pour rÃ©fÃ©rence
sample_df = df.head(50)
sample_df.to_csv('dataset/sample_data.csv', index=False)
print("\nðŸ’¾ Ã‰chantillon sauvegardÃ© : 'dataset/sample_data.csv' (50 premiÃ¨res lignes)")

print("\n" + "="*60)
print("ANALYSE TERMINÃ‰E - RECOMMANDATIONS :")
print("="*60)

print("\nðŸŽ¯ CHOIX POSSIBLES POUR LA PRÃ‰DICTION :")
print("1. Conversion Rate (recommandÃ©) - MÃ©trique business importante")
print("2. Bounce Rate - Comprendre l'engagement")
print("3. Page Views - Mesurer l'intÃ©rÃªt")
print("4. Session Duration - Temps d'engagement")

print("\nðŸ”§ VARIABLES D'ENTRÃ‰E (features) potentielles :")
print("  - Traffic Source (Ã  encoder)")
print("  - Previous Visits")
print("  - Time on Page")
print("  - Page Views")
print("  - Session Duration")

print("\nâš ï¸  ACTIONS REQUISES :")
print("  1. Convertir 'Traffic Source' en variables numÃ©riques (Label Encoding)")
print("  2. Normaliser les donnÃ©es si nÃ©cessaire")
print("  3. Diviser en train/test (80%/20%)")
print("  4. Choisir un modÃ¨le : RandomForestRegressor ou XGBoost")

print("\nðŸš€ Prochaine Ã©tape : ExÃ©cuter 'python scripts/train_model.py'")